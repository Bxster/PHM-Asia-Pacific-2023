{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNutgHEd4hzCZ9kUxjlHtD7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# 1. COLLEGARE GOOGLE DRIVE\n","from google.colab import drive\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","# Questo comando ti chiederà l'autorizzazione per accedere al Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ppqhkg0SbWKF","executionInfo":{"status":"ok","timestamp":1770227135007,"user_tz":-60,"elapsed":1925,"user":{"displayName":"Lil Bxster","userId":"00013610029540758440"}},"outputId":"0dc65d80-c0e5-4ca1-d0d6-d291d2908625"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# --- CONFIGURAZIONE PERCORSI PER COLAB ---\n","# Base directory nel tuo Drive\n","BASE_DIR = \"/content/drive/MyDrive/train/\"\n","\n","# Verifica che i percorsi siano giusti\n","print(f\"Contenuto della cartella train: {os.listdir(BASE_DIR)}\")\n","\n","# Impostiamo i path specifici\n","# Assumo che i CSV siano dentro una sottocartella 'data'.\n","# Se sono direttamente in 'train', cancella la parte 'data/'\n","PATH_TRAIN_DATA = os.path.join(BASE_DIR, \"data/\")\n","PATH_LABELS = os.path.join(BASE_DIR, \"labels.xlsx\")"],"metadata":{"id":"q1X8wBVuwjMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-mfenudZvFw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770221649864,"user_tz":-60,"elapsed":54066,"user":{"displayName":"Lil Bxster","userId":"00013610029540758440"}},"outputId":"3e9d6db5-e48b-4fdb-ec25-356e806e5079"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lettura file labels: /content/drive/MyDrive/Manutenzione/train/labels.xlsx\n","Labels caricate correttamente. Totale casi: 177\n","Inizio estrazione feature dai file in: /content/drive/MyDrive/Manutenzione/train/data/\n","\n","COMPLETATO!\n","File salvato in: /content/drive/MyDrive/Manutenzione/train/dataset_completo_train.csv\n","Dimensioni finali: (177, 76)\n","Prime 5 righe delle colonne Target:\n","   Case  Target_Task1  Target_Task2\n","0     1             0             0\n","1     2             0             0\n","2     3             0             0\n","3     4             0             0\n","4     5             0             0\n"]}],"source":["# --- INIZIO CODICE DI ELABORAZIONE ---\n","\n","def process_labels_and_targets(path_labels):\n","    \"\"\"\n","    Legge l'Excel, mantiene tutte le colonne originali e\n","    aggiunge le colonne Target calcolate per i 5 Task.\n","    \"\"\"\n","    print(f\"Lettura file labels: {path_labels}\")\n","\n","    # header=1 per saltare la riga di raggruppamento\n","    df = pd.read_excel(path_labels, header=1)\n","\n","    # Rinominiamo le prime colonne essenziali\n","    df.rename(columns={\n","        df.columns[0]: 'Case',\n","        df.columns[1]: 'Spacecraft',\n","        df.columns[2]: 'Condition'\n","    }, inplace=True)\n","\n","    # Inizializziamo le colonne Target\n","    df['Target_Task1'] = 0       # 0:Normal, 1:Abnormal\n","    df['Target_Task2'] = 0       # 0:Normal, 1:Unknown, 2:Bubble, 3:Valve\n","    df['Target_Task3'] = 0       # 0:None, 1-8:Bubble Loc\n","    df['Target_Task4'] = 0       # 0:None, 1-4:Valve Loc\n","    df['Target_Task5'] = 100.0   # Ratio\n","\n","    # Mapping per Location\n","    bubble_cols = ['BP1', 'BP2', 'BP3', 'BP4', 'BP5', 'BP6', 'BP7', 'BV1']\n","    valve_cols = ['SV1', 'SV2', 'SV3', 'SV4']\n","\n","    for index, row in df.iterrows():\n","        cond = row['Condition']\n","\n","        # LOGICA TASK 1 & 2\n","        if cond == 'Normal':\n","            df.at[index, 'Target_Task1'] = 0\n","            df.at[index, 'Target_Task2'] = 0\n","        elif cond == 'Anomaly': # Bubble\n","            df.at[index, 'Target_Task1'] = 1\n","            df.at[index, 'Target_Task2'] = 2 # 2 = Bubble\n","        elif cond == 'Fault':   # Valve\n","            df.at[index, 'Target_Task1'] = 1\n","            df.at[index, 'Target_Task2'] = 3 # 3 = Valve Fault\n","\n","        # LOGICA TASK 3 (Bubble)\n","        for i, col in enumerate(bubble_cols):\n","            if col in df.columns and row[col] == 'Yes':\n","                df.at[index, 'Target_Task3'] = i + 1\n","                break\n","\n","        # LOGICA TASK 4 & 5 (Valve)\n","        for i, col in enumerate(valve_cols):\n","            if col in df.columns:\n","                val = row[col]\n","                if isinstance(val, (int, float)) and val < 100:\n","                    df.at[index, 'Target_Task4'] = i + 1\n","                    df.at[index, 'Target_Task5'] = val\n","                    break\n","\n","    return df\n","\n","def extract_features(file_path):\n","    \"\"\"\n","    Estrae le features da un singolo file CSV (1200 righe).\n","    \"\"\"\n","    try:\n","        df = pd.read_csv(file_path)\n","        feats = {}\n","        sensors = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7']\n","\n","        # 1. GLOBAL (tutto il file)\n","        for s in sensors:\n","            sig = df[s]\n","            feats[f'{s}_Global_Mean'] = sig.mean()\n","            feats[f'{s}_Global_Std'] = sig.std()\n","            feats[f'{s}_Global_Max'] = sig.max()\n","            feats[f'{s}_Global_Min'] = sig.min()\n","            feats[f'{s}_Global_PtP'] = sig.max() - sig.min()\n","\n","        # 2. START (primi 100ms)\n","        df_start = df[df['TIME'] <= 0.1]\n","        for s in sensors:\n","            sig = df_start[s]\n","            if len(sig) > 0:\n","                feats[f'{s}_Start_Mean'] = sig.mean()\n","                feats[f'{s}_Start_Std'] = sig.std()\n","                feats[f'{s}_Start_Slope'] = sig.iloc[-1] - sig.iloc[0]\n","            else:\n","                feats[f'{s}_Start_Mean'] = 0\n","                feats[f'{s}_Start_Std'] = 0\n","                feats[f'{s}_Start_Slope'] = 0\n","\n","        return feats\n","    except Exception as e:\n","        print(f\"Errore lettura {file_path}: {e}\")\n","        return None\n","\n","# --- MAIN ESECUZIONE ---\n","if __name__ == \"__main__\":\n","\n","    # 1. Elaboriamo l'Excel\n","    if os.path.exists(PATH_LABELS):\n","        df_labels = process_labels_and_targets(PATH_LABELS)\n","        print(f\"Labels caricate correttamente. Totale casi: {len(df_labels)}\")\n","    else:\n","        print(f\"ERRORE: Non trovo il file labels in {PATH_LABELS}\")\n","        exit()\n","\n","    dataset_rows = []\n","\n","    print(f\"Inizio estrazione feature dai file in: {PATH_TRAIN_DATA}\")\n","\n","    for index, row in df_labels.iterrows():\n","        case_id = int(row['Case'])\n","\n","        # FORMATTAZIONE NOME FILE: Case001.csv\n","        filename = f\"Case{case_id:03d}.csv\"\n","        file_path = os.path.join(PATH_TRAIN_DATA, filename)\n","\n","        if os.path.exists(file_path):\n","            # 2. Calcoliamo le Features\n","            features_dict = extract_features(file_path)\n","\n","            if features_dict:\n","                # 3. MERGE\n","                full_row = {**row.to_dict(), **features_dict}\n","                dataset_rows.append(full_row)\n","        else:\n","            # Utile per capire se il percorso è sbagliato\n","            if index < 3: # Stampiamo l'errore solo per i primi per non intasare\n","                print(f\"File non trovato: {file_path}\")\n","\n","    # 4. Salvataggio su Drive\n","    if len(dataset_rows) > 0:\n","        df_final = pd.DataFrame(dataset_rows)\n","\n","        # Salviamo il file CSV nella stessa cartella 'train' su Drive\n","        output_filename = os.path.join(BASE_DIR, \"dataset_completo_train.csv\")\n","        df_final.to_csv(output_filename, index=False)\n","\n","        print(f\"\\nCOMPLETATO!\")\n","        print(f\"File salvato in: {output_filename}\")\n","        print(f\"Dimensioni finali: {df_final.shape}\")\n","        print(\"Prime 5 righe delle colonne Target:\")\n","        print(df_final[['Case', 'Target_Task1', 'Target_Task2']].head())\n","    else:\n","        print(\"\\nNESSUN DATO ELABORATO. Controlla i percorsi delle cartelle.\")"]},{"cell_type":"code","source":[" # --- CONFIGURAZIONE PERCORSI TEST ---\n","BASE_DIR = \"/content/drive/MyDrive/test/\"\n","PATH_TEST_DATA = os.path.join(BASE_DIR, \"data/\")       # Cartella coi CSV grezzi\n","PATH_TEST_LABELS = os.path.join(BASE_DIR, \"labels_spacecraft.xlsx\") # File info spacecraft\n","\n","def extract_features(file_path):\n","    \"\"\"\n","    STESSA IDENTICA FUNZIONE usata per il training.\n","    È fondamentale che le features siano calcolate allo stesso modo.\n","    \"\"\"\n","    try:\n","        df = pd.read_csv(file_path)\n","        feats = {}\n","        sensors = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7']\n","\n","        # 1. GLOBAL\n","        for s in sensors:\n","            sig = df[s]\n","            feats[f'{s}_Global_Mean'] = sig.mean()\n","            feats[f'{s}_Global_Std'] = sig.std()\n","            feats[f'{s}_Global_Max'] = sig.max()\n","            feats[f'{s}_Global_Min'] = sig.min()\n","            feats[f'{s}_Global_PtP'] = sig.max() - sig.min()\n","\n","        # 2. START (primi 100ms)\n","        df_start = df[df['TIME'] <= 0.1]\n","        for s in sensors:\n","            sig = df_start[s]\n","            if len(sig) > 0:\n","                feats[f'{s}_Start_Mean'] = sig.mean()\n","                feats[f'{s}_Start_Std'] = sig.std()\n","                feats[f'{s}_Start_Slope'] = sig.iloc[-1] - sig.iloc[0]\n","            else:\n","                feats[f'{s}_Start_Mean'] = 0\n","                feats[f'{s}_Start_Std'] = 0\n","                feats[f'{s}_Start_Slope'] = 0\n","        return feats\n","    except Exception as e:\n","        print(f\"Errore {file_path}: {e}\")\n","        return None\n","\n","# --- MAIN ---\n","if __name__ == \"__main__\":\n","    print(f\"Lettura info spacecraft da: {PATH_TEST_LABELS}\")\n","\n","    # Questo file ha solo: Case, Spacecraft\n","    df_info = pd.read_excel(PATH_TEST_LABELS, header=1) # Modificato: aggiunto header=1\n","\n","    dataset_rows = []\n","\n","    print(\"Inizio elaborazione TEST set...\")\n","\n","    for index, row in df_info.iterrows():\n","        case_id = int(row['Case#']) # Modificato: cambiato 'ID' in 'Case#'\n","        # Nota: controlla se nel file excel la colonna è 'ID' o 'Case'.\n","        # Solitamente nei file labels_spacecraft è 'ID'.\n","\n","        filename = f\"Case{case_id}.csv\" # Qui di solito non hanno padding 001, ma controlliamo\n","        # Se i file si chiamano Case178.csv (senza zeri extra davanti se >100)\n","\n","        file_path = os.path.join(PATH_TEST_DATA, filename)\n","\n","        if not os.path.exists(file_path):\n","             # Proviamo col padding se fallisce (es Case001.. ma qui siamo >100)\n","             # Di solito nel test set i nomi sono Case178.csv\n","             pass\n","\n","        if os.path.exists(file_path):\n","            feats = extract_features(file_path)\n","            if feats:\n","                # Aggiungiamo ID e Spacecraft\n","                full_row = {\n","                    'Case': case_id,\n","                    'Spacecraft': row['Spacecraft#'], # Modificato: cambiato 'Spacecraft' in 'Spacecraft#'\n","                    **feats\n","                }\n","                dataset_rows.append(full_row)\n","        else:\n","            print(f\"File mancante: {filename}\")\n","\n","    # Salvataggio\n","    df_final = pd.DataFrame(dataset_rows)\n","    output_file = os.path.join(BASE_DIR, \"dataset_completo_test.csv\")\n","    df_final.to_csv(output_file, index=False)\n","\n","    print(f\"\\nGenerazione completata!\")\n","    print(f\"File salvato: {output_file}\")\n","    print(f\"Dimensioni: {df_final.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzEng_ktwb2G","executionInfo":{"status":"ok","timestamp":1770227368607,"user_tz":-60,"elapsed":15347,"user":{"displayName":"Lil Bxster","userId":"00013610029540758440"}},"outputId":"6aa2a770-ad51-46a5-c071-2317c94a1b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Lettura info spacecraft da: /content/drive/MyDrive/Manutenzione/test/labels_spacecraft.xlsx\n","Inizio elaborazione TEST set...\n","\n","Generazione completata!\n","File salvato: /content/drive/MyDrive/Manutenzione/test/dataset_completo_test.csv\n","Dimensioni: (46, 58)\n"]}]}]}